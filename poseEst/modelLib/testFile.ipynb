{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from models.PoseDetector import PoseDetector\n",
    "from dataset import PoseDataset\n",
    "import utils\n",
    "import config"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "images = os.listdir(./datasets/YogaVidCollected/Yoga_Vid_Collected')\n",
    "    # one problem that can be faced here is all videos may not split\n",
    "    # well as few types of them may not be found in test set\n",
    "train_images_names, val_images_names = utils.train_test_split(\n",
    "        images, config.SPLIT)\n",
    "print('\\n------------Creating Dataset Objects------------\\n')\n",
    "train_data = PoseDataset(root_path=config.root_path,\n",
    "                             videos_name_list=train_images_names)\n",
    "val_data = PoseDataset(root_path=config.root_path,\n",
    "                           videos_name_list=val_images_names)\n",
    "print('\\n------------Completed Dataset Creation-----------\\n')\n",
    "\n",
    "print('\\n----------------Creating DataLoaders-------------\\n')\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "        train_data, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(\n",
    "        val_data, batch_size=config.BATCH_SIZE, shuffle=False)\n",
    "print('\\n----------------Dataloaders Done-----------------\\n')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------Creating Dataset Objects------------\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'root_path'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-921e1ac6c41a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         images, config.SPLIT)\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n------------Creating Dataset Objects------------\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m train_data = PoseDataset(root_path=config.root_path,\n\u001b[0m\u001b[1;32m      8\u001b[0m                              videos_name_list=train_images_names)\n\u001b[1;32m      9\u001b[0m val_data = PoseDataset(root_path=config.root_path,\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'root_path'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Bhuj'"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "4b4062da570dba819870cf4402bf0723ab81dd038c9a4839e15b893ff66984c8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}